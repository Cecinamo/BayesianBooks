---
title: "Ratings"
author: "Cecilia Martinez Oliva"
header-includes:
- \usepackage{courier}
geometry: "left=2cm,right=2cm,top=1.5cm,bottom=1.5cm"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(fig.pos = 'H')
knitr::opts_chunk$set(results = "hold")
# asis altrimenti
knitr::opts_chunk$set(fig.show = 'hold')
```

\section{1. Dataset}
#### I have analysed 185973 books rated by 77805 users, with 433671 rating. In order to avoid too many missing values, I shrinked the sample in a cluster where each book was rated by at least 50% of the users. 
```{r 1. ratings, fig.height = 3, fig.width = 6, fig.align = "center"}
# data
setwd('D:/DataScience/SDS2/Books')
set.seed(1234)
r = as.matrix(read.csv("Books.csv")[2:12])
NUsers = dim(r)[1]
NBooks = dim(r)[2]
cat(paste('N users:', NUsers, '\n'))
cat(paste('N books:', NBooks, '\n'))
cat(paste('Missing values:',sum(is.na(r))/length(c(r))),'\n')
c('Mean' = mean(r, na.rm = T), 'SD' = sd(r, na.rm = T))
par(mar = c(2,2,2,2))
hist(r, col = 'black', breaks = 1:10, main = 'Ratings')
```
#### I obtained a dataset with 20 users, 11 books, and 28% of missing values. The average rate is 8.34 with standard deviation of 1.28.
\subsection{1.1 Users}
```{r 1.1 users, fig.height = 3, fig.width = 10, fig.align = "center"}
par(mfrow=c(1,5))
v = rep(NA, dim(r)[1]) 
hist(r[1,], col = 'black', breaks = 1:10, xlab = paste('user',1), main='')
v[1] = mean(r[1,], na.rm = T)
title("\n Users' ratings", outer=TRUE)
for(i in 2:dim(r)[1]) {
  hist(r[i,], col = 'black', breaks = 1:10, 
       xlab = paste('user',i), main='')
  v[i] = mean(r[i,], na.rm = T)
}
cat(paste('SD:', sd(v), '\n'))
```
#### About 50% of the users have given the same rating to all the books they read. The standard deviation between the average ratings of the users is 1.15.
\subsection{1.2 Books}
```{r 1.2 books, fig.height = 3, fig.width = 10, fig.align = "center"}
par(mfrow=c(1,5))
v = rep(NA, dim(r)[2]) 
hist(r[,1], col = 'black', breaks = 1:10, xlab = paste('book',1), main='')
v[1] = mean(r[,1], na.rm = T)
title("\n Books' ratings", outer=TRUE)
for(i in 2:(dim(r)[2])) {
  hist(r[,i], col = 'black', breaks = 1:10, 
       xlab = paste('book',i), main='')
  v[i] = mean(r[,i], na.rm = T)
}
cat(paste('SD:', sd(v), '\n'))
```

```{r 1. data}
ratings = r-1 # da 0 a 9
user.m = apply(ratings,1,mean, na.rm=T)
book.m = apply(ratings,2,mean, na.rm=T)
ratings = structure(.Data = c(ratings), .Dim = c(NUsers,NBooks))
```
#### Ratings given to each book are more heterogeneous and the standard deviation between the average ratings of the books is 0.24, lower than the users' one (1.15).

\section{2. Model: random effects on users and books}
#### We can suppose that each rating given by a user to a book depends both on the user and the book. $\phi_i$ is the influence of user i on rating$_{ij}$, while $\gamma_j$ is the influence of book j. $\alpha$ is a constant. \hfill\break We suppose that $\phi$s, $\gamma$s and $\alpha$ are generated by normal distributions with 0 mean and $\tau_u$, $\tau_b$ and $\tau_{\alpha}$ precisions, respectively.\hfill\break $\tau_u$, $\tau_b$, and $\tau_{\alpha}$ have gamma's prior distributions.\hfill\break The original ratings had values from 1 to 10 so we want to predict ratings-1 distributed as a binomial distribution with n=9 and p=$\theta_{ij}$. I am going to call them ratings$_{ij}$ instead of ratings$_{ij}$-1 for semplicity.\hfill\break Logit of $\theta{ij}$ is equal to $\alpha$+$\phi_i$+$\gamma_j$ to allow $\theta_{ij}$ to take values in (0,1).
```{r 2. DAG, echo=F, include=T, warning=F, message=F}
library(igraph)
g = graph.empty(n = 11, directed = T)
names = c(expression(tau[alpha]),expression(tau[phi]),expression(tau[gamma]),
          expression(alpha), expression(phi[i]), expression(gamma[j]),
          expression(theta[ij]),
          expression(r[ij]))
V(g)$name = names
l = c(0,0.5, 0,0, 0,-0.5, 1,0.5, 1,0, 1,-0.5, 2,0,  3,0)
layout = matrix(l, nrow = 11, ncol = 2, byrow = T)

g = add.edges(g,c(1,4, 2,5, 3,6, 4,7, 5,7, 6,7, 7,8))
plot(g, edge.color = rgb(0,0,0,.1), edge.arrow.size = .3, 
     vertex.label.font = 3, edge.width = 1, vertex.size = 30, 
     vertex.shape = 'none', vertex.label.cex = .8, vertex.label.dist = 0,
     vertex.label.color = 'black', layout = layout)

```

####\hfill\break\hfill\break $rating_{ij}\sim Binom(9,\theta_{ij})\hspace{2.5cm}where\hspace{.5cm}logit(\theta_{ij})=\alpha+\phi_i+\gamma_j$
####$\alpha\sim N(0,\tau_\alpha),\hspace{1cm}\tau_\alpha\sim Gamma(a,b)\hspace{5cm}$
####$\phi_i\sim N(0,\tau_u),\hspace{1cm}\tau_u\sim Gamma(a,b)\hspace{2cm}for\hspace{.2cm} i=1,..Nusers$
####$\gamma_j\sim N(0,\tau_b),\hspace{1cm}\tau_b\sim Gamma(a,b)\hspace{2cm}for\hspace{.2cm} j=1,..Nbooks$ \hfill\break\hfill\break

#### MODEL
$\texttt{model \{} \\$
$\texttt{\hspace*{1cm}for (i in 1:Nusers) \{} \\$
$\texttt{\hspace*{2cm}for (j in 1:Nbooks) \{} \\$
$\texttt{\hspace*{3cm}ratings[i,j]}$$\sim$$\texttt{dbin(theta[i,j],9)} \\$
$\texttt{\hspace*{3cm}logit.theta[i,j] <- alpha + phi[i] + gamma[j]} \\$
$\texttt{\hspace*{3cm}theta[i,j] <- exp(logit.theta[i,j])/(1+exp(logit.theta[i,j]))} \\$
$\texttt{\hspace*{2cm}\}} \\$
$\texttt{\hspace*{2cm}phi[i]}$$\sim$$\texttt{dnorm(0, tau.u)} \\$
$\texttt{\hspace*{1cm}\}} \\$
$\texttt{\hspace*{1cm}for(j in 1:Nbooks) \{} \\$
$\texttt{\hspace*{2cm}gamma[j]}$$\sim$$\texttt{dnorm(0, tau.b)} \\$
$\texttt{\hspace*{1cm}\}} \\$
$\texttt{\hspace*{1cm}alpha}$$\sim$$\texttt{dnorm(0, tau.alpha)} \\$
$\texttt{\hspace*{1cm}tau.u}$$\sim$$\texttt{dgamma(a.u, b.u)} \\$
$\texttt{\hspace*{1cm}tau.b}$$\sim$$\texttt{dgamma(a.b, b.b)} \\$
$\texttt{\hspace*{1cm}tau.alpha}$$\sim$$\texttt{dgamma(a.alpha, b.alpha)} \\$
$\texttt{\}} \\$

#### We can try two different parametrizations for the hyperparameters of the gammas' distributions to estimate the $\alpha$'s, $\phi$s' and $\gamma$s' precisions.

```{r 2. two gamma, fig.height = 4, fig.width = 10, fig.align = "center"}
curve(dgamma(x,1,1), xlim = c(-.1,5), ylim = c(-.1,1), lwd = 2, ylab = '')
curve(dgamma(x,0.001,0.001), add = T, col = 'red', lwd = 2)
legend('topright', c('gamma(1,1)', 'gamma(0.01,0.01)'),
                    col = c('black', 'red'), lwd = c(2,2), cex = 1)
```

#### We can try 4 different models. In the first one and the third one the hyperparameters for the Gamma distributions are a=b=0.001. In order to balance the weigths of $\phi$ and $\gamma$, in the second model and the fourth one the hyperparameters are set as a=b=1. Finally to achieve better autocorrelations for the $\alpha$ parameter we can use the R2WinBugs to perform over-relaxation in the third and fourth model. 
```{r 2. run models, message=F, warning=F, fig.height = 20, fig.width = 15, fig.align = "center"}
library(R2jags)
library(R2WinBUGS)
data1 = list(Nusers = NUsers, Nbooks = NBooks, ratings = ratings, 
             a.u = .001, b.u = .001, a.b = .001, b.b = .001, 
             a.alpha = .001, b.alpha = .001)
data2 = list(Nusers = NUsers, Nbooks = NBooks, ratings = ratings, 
             a.u = 1, b.u = 1, a.b = 1, b.b = 1, 
             a.alpha = 1, b.alpha = 1)

inits = list(alpha = 0,
             phi = rep(0,NUsers),
             gamma = rep(0,NBooks), 
             tau.u = 0.1, tau.b = 0.1, tau.alpha = 0.1)
mod1 = jags(data = data1,
           inits = list(inits),
           n.chain = 1,
           parameters.to.save=c("tau.u", "tau.b", "tau.alpha",
                                "phi","gamma","alpha"),
           model.file="model01.txt",
           n.iter = 10000,
           n.burnin = 0,
           n.thin = 1)

mod2 = jags(data = data2,
           inits = list(inits),
           n.chain = 1,
           parameters.to.save=c("tau.u", "tau.b", "tau.alpha",
                                "phi","gamma","alpha"),
           model.file="model01.txt",
           n.iter = 10000,
           n.burnin = 0,
           n.thin = 1)
dir = 'C:/Users/cecin/Downloads/winbugs14_unrestricted/WinBUGS14'
wb.mod = bugs(data = data1,
              inits = list(inits),
              n.chains = 1,
              parameters.to.save=c("tau.u", "tau.b", "tau.alpha",
                                   "phi","gamma","alpha"),
              model.file = 'model01.txt',
              n.iter = 10000,
              n.burnin = 0,
              n.thin = 1,
              bugs.directory = dir,
              over.relax = T)

wb.mod2 = bugs(data = data2,
              inits = list(inits),
              n.chains = 1,
              parameters.to.save=c("tau.u", "tau.b", "tau.alpha",
                                   "phi","gamma","alpha"),
              model.file = 'model01.txt',
              n.iter = 10000,
              n.burnin = 0,
              n.thin = 1,
              bugs.directory = dir,
              over.relax = T)
```

```{r 2. print functions}
d = '----------------------------------------------------------------------\n'
print.jags.output2 = function(model1,model2,par,sd=F,r=2, t='') {
  m = par
  for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
  cat(paste(m,'\n'))
  if(sd) {
    print(c('mean1' = round(model1$mean[[par]], digits=r),
            'as.sd1' = round(1/sqrt(model1$mean[[par]]), digits=r),
            'sd1' = round(model1$sd[[par]], digits=r),
            'mean2' = round(model2$mean[[par]],digits=r), 
            'as.sd1' = round(1/sqrt(model2$mean[[par]]), digits=r),
            'sd2' = round(model2$sd[[par]], digits=r)))
  }
  else{
    print(c('mean1' = round(model1$mean[[par]], digits=r),
            'sd1' = round(model1$sd[[par]], digits=r),
            'mean2' = round(model2$mean[[par]],digits=r), 
            'sd2' = round(model2$sd[[par]], digits=r)))
  }
  par(mfrow = c(1,2))
  par(oma=c(0,0,2,0))
  plot(model1$sims.array[,1,par], type='l', xlab='iterations',
       ylab='traceplot', main='model1', cex.lab=2, cex.axis=2, cex.main=2)
  title(t, cex.main=2, outer=TRUE)
  plot(model2$sims.array[,1,par], type='l', xlab='iterations', 
       ylab='traceplot', main='model2', cex.lab=2, cex.axis=2, cex.main=2)
  par(oma=c(0,0,0,0))
  n1 = length(model1$sims.array[,1,par])
  n2 = length(model2$sims.array[,1,par])
  plot(density(model1$sims.array[,1,par]), type='l', xlab='', 
       ylab='density', main='', cex.lab=2, cex.axis=2, cex.main=2)
  plot(density(model2$sims.array[,1,par]), type='l', xlab='', 
       ylab='density', main='', cex.lab=2, cex.axis=2, cex.main=2)
  acf(model1$sims.array[,1,par], lag.max=50, 
      main='', cex.lab=2, cex.axis=2, cex.main=2)
  acf(model2$sims.array[,1,par], lag.max=50, 
      main='', cex.lab=2, cex.axis=2, cex.main=2)
  plot(cumsum(model1$sims.array[,1,par])/1:n1, type="l", xlab = '',
       ylab='running means', main='', cex.lab=2, cex.axis=2, cex.main=2)
  plot(cumsum(model2$sims.array[,1,par])/1:n2, type="l", xlab = '',
       ylab='running means', main='', cex.lab=2, cex.axis=2, cex.main=2)
}

print.jags.output1 = function(model,par,t='',sd=F,r=2, wb=F) {
  if(wb==F) {
    model = model$BUGSoutput
  }
  m = par
  for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
  cat(paste(m,'\n'))
  if(sd) {
    print(c('mean1' = round(model$mean[[par]], digits=r),
            'as.sd1' = round(1/sqrt(model$mean[[par]]), digits=r),
            'sd1' = round(model$sd[[par]], digits=r)))
  }
  else{
    print(c('mean1' = round(model$mean[[par]], digits=r),
            'sd1' = round(model$sd[[par]], digits=r)))
  }
  par(mfrow = c(1,2))
  #par(mar = c(2,2,6,2))
  par(oma=c(0,0,2,0))
  n = length(model$sims.array[,1,par])
  plot(model$sims.array[,1,par], type='l', xlab='iterations',
       ylab='traceplot', main='', cex.lab=2, cex.axis=2, cex.main=2)
  title(t, cex.main=2, outer=TRUE)
  plot(density(model$sims.array[,1,par]), type='l', xlab='', 
       ylab='density', main='', cex.lab=2, cex.axis=2, cex.main=2)
  acf(model$sims.array[,1,par], lag.max=50, 
      main='', cex.lab=2, cex.axis=2, cex.main=2)
  plot(cumsum(model$sims.array[,1,par])/1:n, type="l", xlab = '',
       ylab='running means', main='', cex.lab=2, cex.axis=2, cex.main=2)
}

phi.gamma.jags.output = function(models, mnames, r=3) {
  pars = c('phi','gamma')
  for(par in pars) {
    m = par
    for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
    cat(paste(m,'\n'))
    app = c()
    n = c()
    for(m in 1:length(models)) {
      app = c(app,c(round(mean(models[[m]]$mean[[par]]), digits=r),
                    round(sd(models[[m]]$mean[[par]]), digits=r)))
      n = c(n, c(paste('mean',m,sep='')), c(paste('sd',m,sep='')))
    }
    names(app) = n
    print(app)
  }
  par(mfrow = c(1,2))
  cols = c('green','blue','darkgreen')
  lwds = c(1,2,1)
  pchs = c(4,3,3)
  cexs = c(2,2,2)
  for(par in pars) {
    names = c('model1')
    colors = c('lightblue')
    ls = c(2)
    ps = c(4)
    cs = c(2)
    label = eval(parse(text=paste('expression(',par,')')))
    plot(models[[1]]$mean[[par]], pch=4, cex=2, col='lightblue',
         xlab=label, ylab='', ylim=c(-2,2), lwd=2,
         main = '', cex.lab = 2)
    for(m in 2:length(models)) {
      points(models[[m]]$mean[[par]], pch=pchs[m-1], cex=cexs[m-1], 
             col=cols[m-1], lwd=lwds[m-1])
      #names = c(names,paste('model',m,sep=''))
      names = mnames
      colors = c(colors,c(cols[m-1]))
      ls=c(ls,c(lwds[m-1]))
      ps=c(ps,c(pchs[m-1]))
      cs=c(cs,c(cexs[m-1]))
    }
    legend('topleft', names, col=colors, pch=ps, pt.cex=cs,
           pt.lwd=ls)
  }
}
```
\newpage

\subsection{2.1 tau.u}
\vspace*{.5cm}
```{r 2. tau.u, fig.height = 5, fig.width = 20}
print.jags.output2(mod1[[2]],mod2[[2]],'tau.u',sd=T)
print.jags.output2(wb.mod,wb.mod2, 'tau.u',t='with over-relaxation',sd=T)
```

##### $\tau_u$ does not change so much between model1, model2 and model2(wo) but it significantly increases in model1(wo).
\newpage
\subsection{2.2 tau.b}
\vspace*{.5cm}
```{r 2. tau.b, fig.height = 5, fig.width = 20}
print.jags.output2(mod1[[2]],mod2[[2]],'tau.b', sd=T)
print.jags.output2(wb.mod,wb.mod2,'tau.b',t='with over-relaxation',sd=T)
```

##### $\tau_b$ instead decreases a lot with the second hyperparameters (a=b=1), meaning that there are more differences between the books. Also the standard deviation and autocorrelations decrease.
\newpage
\subsection{2.3 tau.alpha}
\vspace*{.5cm}
```{r 2. tau.alpha, fig.height = 5, fig.width = 20}
print.jags.output2(mod1[[2]],mod2[[2]],'tau.alpha', sd=T)
print.jags.output2(wb.mod,wb.mod2,'tau.alpha',t='with over-relaxation',sd=T)
```
\newpage
\subsection{2.4 alpha}
\vspace*{.5cm}
```{r 2. alpha, fig.height = 5, fig.width = 20}
print.jags.output2(mod1[[2]],mod2[[2]],'alpha')
print.jags.output2(wb.mod,wb.mod2,'alpha',t='with over-relaxation')
```

##### $\alpha$ remains quite stable in the four models. In this case even with lag=50 autocorrelations are high. They are lower with over-relaxation. $Logit(\alpha)\simeq 0.85$ multiplied by 9 is $\simeq 7.65$ which is near to the average rating.
\newpage
\subsection{2.5 phi and gamma}
\vspace*{.5cm}
```{r 2. phi and gamma, fig.height = 6, fig.width = 10, fig.align = "center"}
phi.gamma.jags.output(list(mod1[[2]],mod2[[2]],wb.mod,wb.mod2), 
                      mnames = c('model1','model2','model1(wo)', 
                                 'model2(wo)'))
cat('\n')
c('DIC1'=mod1[[2]]$DIC, 'DIC2'=mod2[[2]]$DIC, 'DIC1(wo)'=wb.mod$DIC, 
  'DIC2(wo)'=wb.mod2$DIC)
```

##### Finally we can visualize the different estimations for the $\phi$s and $\gamma$s parameters. Model2 has bigger $\gamma$s then the other models but not so much.
\newpage
\subsection{2.6 model1 results}
\vspace*{.5cm}
```{r 2. plot mod1}
plot(mod1)
```
\newpage
```{r 2. mod1}
m = 'model1'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
mod1[[2]]
DIC1 = mod1[[2]]$DIC
dev1 = mod1[[2]]$mean[['deviance']]
```
\newpage
\subsection{2.7 model2 results}
\vspace*{.5cm}
```{r 2. plot mod2}
plot(mod2)
```
\newpage
```{r 2. mod2}
m = 'model2'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
mod2[[2]]
DIC2 = mod2[[2]]$DIC
dev2 = mod2[[2]]$mean[['deviance']]
```
\newpage
\subsection{2.8 model1 with over-relaxation results}
\vspace*{.5cm}
```{r 2. plot mod1 wo}
plot(wb.mod)
```
\newpage
```{r 2. mod1 wo}
m = 'model1 with over-relaxation'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
wb.mod
DIC1wo = wb.mod$DIC
dev1wo = wb.mod$mean[['deviance']]
```
\newpage
\subsection{2.9 model2 with over-relaxation}
\vspace*{.5cm}
```{r 2. plot mod2 wo}
plot(wb.mod2)
```
\newpage
```{r 2. mod2 wo}
m = 'model2 with over-relaxation'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
wb.mod2
DIC2wo = wb.mod2$DIC
dev2wo = wb.mod2$mean[['deviance']]
```

\section{3. Simulations}
```{r 3. simulations, results="hide", eval=T}
alpha = wb.mod2$mean$alpha
tau.u = wb.mod2$mean$tau.u
tau.b = wb.mod2$mean$tau.b

run.model = function(p) {
  dir = 'C:/Users/cecin/Downloads/winbugs14_unrestricted/WinBUGS14'
  mod = bugs(data = p$data,
             inits = list(p$inits),
             n.chains = 1,
             parameters.to.save= p$pts,
             model.file = p$file,
             n.iter = p$niter,
             n.burnin = p$nburnin,
             n.thin = p$nthin,
             bugs.directory = dir,
             over.relax = T)
  return(mod)
}

inits = list(alpha = 0,
             phi = rep(0,NUsers),
             gamma = rep(0,NBooks),
             tau.u = 0.1, tau.b = 0.1, tau.alpha = 0.1)
pts = c("tau.u", "tau.b", "tau.alpha", "phi", "gamma", "alpha")
file = 'model01.txt'
data = list(Nusers = NUsers, Nbooks = NBooks,
            a.u = 1, b.u = 1, a.b = 1, b.b = 1,
            a.alpha = 1, b.alpha = 1)

model = list('data'=data, 'inits'=inits, 'pts'=pts, 'file'=file,
             'niter'=1000, 'nburnin'=0, 'nthin'=1)
n = 100
alpha.res = rep(NA,n)
tau.u.res = rep(NA,n)
tau.b.res = rep(NA,n)

alpha.nan.res = rep(NA,n)
tau.u.nan.res = rep(NA,n)
tau.b.nan.res = rep(NA,n)

p = round(.28*(NUsers*NBooks)) # NA

for(i in 1:n) {
  phi.sim = rnorm(NUsers,0,1/sqrt(tau.u))
  gamma.sim = rnorm(NBooks,0,1/sqrt(tau.b))
  ratings.sim = matrix(NA, NUsers, NBooks)
  for(r in 1:NUsers) {
    for(c in 1:NBooks) {
      logit.theta.sim = alpha + phi.sim[r] + gamma.sim[c]
      theta.sim = exp(logit.theta.sim)/(1+exp(logit.theta.sim))
      ratings.sim[r,c] = rbinom(1,9,theta.sim)
    }
  }
  model$data$ratings = structure(.Data = c(ratings.sim), 
                                 .Dim = c(NUsers,NBooks))
  #print(model)
  res = run.model(model)
  alpha.res[i] = res$mean$alpha
  tau.u.res[i] = res$mean$tau.u
  tau.b.res[i] = res$mean$tau.b
  # with NA
  ratings.sim.nan = ratings.sim
  ratings.sim.nan[sample(1:length(ratings))[1:p]] = NA
  model$data$ratings = structure(.Data = c(ratings.sim.nan),
                                 .Dim = c(NUsers,NBooks))
  #print(model)
  res = run.model(model)
  alpha.nan.res[i] = res$mean$alpha
  tau.u.nan.res[i] = res$mean$tau.u
  tau.b.nan.res[i] = res$mean$tau.b
}
```
```{r 3. simluations plots, fig.height = 5, fig.width = 20, fig.align = "center", eval=T}
par(mfrow=c(1,3))
par(oma=c(0,0,2,0))
dens.alpha = approxfun(density(alpha.res)$x, density(alpha.res)$y, 
                       yleft=0, yright=0)
dens.tau.u = approxfun(density(tau.u.res)$x, density(tau.u.res)$y, 
                       yleft=0, yright=0)
dens.tau.b = approxfun(density(tau.b.res)$x, density(tau.b.res)$y, 
                       yleft=0, yright=0)
plot(dens.alpha, main = expression(alpha), xlab = '', ylab = '', 
     xlim = c(0, 2*alpha), cex.lab=2, cex.axis=2, cex.main=3)
abline(v=alpha, lwd = 1.5, col = 'red')
plot(dens.tau.u, main = expression(tau[u]), xlab = '', ylab = '', 
     xlim = c(0, 2*tau.u), cex.lab=2, cex.axis=2, cex.main=3)
abline(v=tau.u, lwd = 1.5, col = 'red')
plot(dens.tau.b, main = expression(tau[b]), xlab = '', ylab = '', 
     xlim = c(0, 2*tau.b), cex.lab=2, cex.axis=2, cex.main=3)
abline(v=tau.b, lwd = 1.5, col = 'red')
c('alpha'=round(integrate(dens.alpha, -Inf, alpha)$value,2),
  'tau.u'=round(integrate(dens.tau.u, -Inf, tau.u)$value,2),
  'tau.b'=round(integrate(dens.tau.b, -Inf, tau.b)$value,2))
dens.alpha.nan = approxfun(density(alpha.nan.res)$x, density(alpha.nan.res)$y,
                           yleft=0, yright=0)
dens.tau.u.nan = approxfun(density(tau.u.nan.res)$x, density(tau.u.nan.res)$y, 
                           yleft=0, yright=0)
dens.tau.b.nan = approxfun(density(tau.b.nan.res)$x, density(tau.b.nan.res)$y, 
                           yleft=0, yright=0)
plot(dens.alpha.nan, main = expression(alpha), xlab = '', ylab = '', 
     xlim = c(0, 2*alpha), cex.lab=2, cex.axis=2, cex.main=3)
abline(v=alpha, lwd = 1.5, col = 'red')
title('with missing value', cex.main=4, outer=TRUE)
plot(dens.tau.u.nan, main = expression(tau[u]), xlab = '', ylab = '', 
     xlim = c(0, 2*tau.u), cex.lab=2, cex.axis=2, cex.main=3)
abline(v=tau.u, lwd = 1.5, col = 'red')
plot(dens.tau.b.nan, main = expression(tau[b]), xlab = '', ylab = '', 
     xlim = c(0, 2*tau.b), cex.lab=2, cex.axis=2, cex.main=3)
abline(v=tau.b, lwd = 1.5, col = 'red')
cat('with missing values\n')
c('alpha'=round(integrate(dens.alpha.nan, -Inf, alpha)$value,2),
  'tau.u'=round(integrate(dens.tau.u.nan, -Inf, tau.u)$value,2),
  'tau.b'=round(integrate(dens.tau.b.nan, -Inf, tau.b)$value,2))
```

#### Now we want to simulate the ratings from our model, fixing $\tau_u=0.67$, $\tau_b=4.53$ and $\alpha=1.69$, to test how good we can recover those parameters. We run 100 simulations and then plot the distribution of the results. The red line is the real value of the parameter. The real dataset had 28% of missing values so in the first case we try to recover the parameters without missing values, in the second case instead I added 62 NA randomly. The two estimations are very similar. $\tau_b$ is underestimated in both cases.
\newpage
\section{4. Diagnostics}
```{r 4. diagnostics + errors}
n = 10000
ratings.hat1 = matrix(NA, NUsers, NBooks)
ratings.hat2 = matrix(NA, NUsers, NBooks)
ratings.hat3 = matrix(NA, NUsers, NBooks)
ratings.hat4 = matrix(NA, NUsers, NBooks)
alpha.sim1 = mod1$BUGSoutput$sims.array[,1,'alpha']
alpha.sim2 = mod2$BUGSoutput$sims.array[,1,'alpha']
alpha.sim3 = wb.mod$sims.array[,1,'alpha']
alpha.sim4 = wb.mod2$sims.array[,1,'alpha']

for(i in 1:NUsers) {
  phi.sim1 = mod1$BUGSoutput$sims.array[,1,paste('phi[',i,']', sep = '')]
  phi.sim2 = mod2$BUGSoutput$sims.array[,1,paste('phi[',i,']', sep = '')]
  phi.sim3 = wb.mod$sims.array[,1,paste('phi[',i,']', sep = '')]
  phi.sim4 = wb.mod2$sims.array[,1,paste('phi[',i,']', sep = '')]
  for(j in 1:NBooks) {
    gamma.sim1 = mod1$BUGSoutput$sims.array[,1,paste('gamma[',j,']', sep = '')]
    gamma.sim2 = mod2$BUGSoutput$sims.array[,1,paste('gamma[',j,']', sep = '')]
    gamma.sim3 = wb.mod$sims.array[,1,paste('gamma[',j,']', sep = '')]
    gamma.sim4 = wb.mod2$sims.array[,1,paste('gamma[',j,']', sep = '')]
    r1 = rep(NA, n)
    r2 = rep(NA, n)
    r3 = rep(NA, n)
    r4 = rep(NA, n)
    for(k in 1:n) {
      logit.theta1 = alpha.sim1[k] + phi.sim1[k] + gamma.sim1[k]
      logit.theta2 = alpha.sim2[k] + phi.sim2[k] + gamma.sim2[k]
      logit.theta3 = alpha.sim3[k] + phi.sim3[k] + gamma.sim3[k]
      logit.theta4 = alpha.sim4[k] + phi.sim4[k] + gamma.sim4[k]
      theta1 =  exp(logit.theta1)/(1+exp(logit.theta1))
      theta2 =  exp(logit.theta2)/(1+exp(logit.theta2))
      theta3 =  exp(logit.theta3)/(1+exp(logit.theta3))
      theta4 =  exp(logit.theta4)/(1+exp(logit.theta4))
      r1[k] = rbinom(1,9,theta1)
      r2[k] = rbinom(1,9,theta2)
      r3[k] = rbinom(1,9,theta3)
      r4[k] = rbinom(1,9,theta4)
    }
    ratings.hat1[i,j] = round(mean(r1))
    ratings.hat2[i,j] = round(mean(r2))
    ratings.hat3[i,j] = round(mean(r3))
    ratings.hat4[i,j] = round(mean(r4))
  }
}
m = 'MODEL1'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
cat(paste('sum of errors:',sum(abs(ratings.hat1-ratings), na.rm=T),
          '\n'))
cat(paste('precision:',
          round(sum((ratings.hat1-ratings)==0, na.rm=T)/sum(is.na(ratings)==F),3),
          '\n'))
m = 'MODEL2'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
cat(paste('sum of errors:',sum(abs(ratings.hat2-ratings), na.rm=T),
          '\n'))
cat(paste('precision:',
          round(sum((ratings.hat2-ratings)==0, na.rm=T)/sum(is.na(ratings)==F),3),
          '\n'))
m = 'MODEL1(wo)'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
cat(paste('sum of errors:',sum(abs(ratings.hat3-ratings), na.rm=T),
          '\n'))
cat(paste('precision:',
          round(sum((ratings.hat3-ratings)==0, na.rm=T)/sum(is.na(ratings)==F),3),
          '\n'))

m = 'MODEL2(wo)'
for(p in 1:(76-nchar(m))) {m=paste(m,'-',sep='')}
cat(paste(m,'\n'))
cat(paste('sum of errors:',sum(abs(ratings.hat4-ratings), na.rm=T),
          '\n'))
cat(paste('precision:',
          round(sum((ratings.hat4-ratings)==0, na.rm=T)/sum(is.na(ratings)==F),3), 
          '\n'))
```


```{r 4. diagnostics users, fig.height = 3, fig.width = 10, fig.align = "center"}
par(mfrow=c(1,4))
plot(ratings.hat1[1,], pch=3, cex=1.5, col='black', lwd=2,
     xlab=paste('user',1), ylab = '', ylim=c(3,9))
points(ratings.hat2[1,], pch=4, cex=1.5, col='red', lwd=2)
points(ratings.hat3[1,], pch=8, cex=1.5, col='green', lwd=1)
points(ratings.hat4[1,], pch=8, cex=1, col='blue', lwd=1)
points(ratings[1,], pch=21, cex=1, bg='white', lwd=1.5)
legend('bottomright', c('ratings','model1','model2','model1(wo)','model2(wo)'),
       col=c('black','black','red','green','blue'), pch=c(21,3,4,8,8),
       pt.cex=c(1,1.5,1.5,1.5,1), pt.lwd = c(1.5,2,2,1,1))
title("\n Users' ratings", outer=TRUE, cex.main =2)
for(i in 2:NUsers) {
  plot(ratings.hat1[i,], pch=3, cex=1.5, col='black', lwd=2,
       xlab=paste('user',i), ylab = '', ylim=c(3,9))
  points(ratings.hat2[i,], pch=4, cex=1.5, col='red', lwd=2)
  points(ratings.hat3[i,], pch=8, cex=1.5, col='green', lwd=1)
  points(ratings.hat4[i,], pch=8, cex=1, col='blue', lwd=1)
  points(ratings[i,], pch=21, cex=1, bg='white', lwd=1.5)
  legend('bottomright', c('ratings','model1','model2','model1(wo)','model2(wo)'),
         col=c('black','black','red','green','blue'), pch=c(21,3,4,8,8),
         pt.cex=c(1,1.5,1.5,1.5,1), pt.lwd = c(1.5,2,2,1,1))
}
```

#### Model2 for book5 has the biggest $\gamma$(=-0.3).
```{r 4. diagnostic books, fig.height = 3, fig.width = 10, fig.align = "center"}
par(mfrow=c(1,4))
plot(ratings.hat1[,1], pch=3, cex=1.5, col='black', lwd=2,
     xlab=paste('book',1), ylab = '', ylim=c(3,9))
points(ratings.hat2[,1], pch=4, cex=1.5, col='red', lwd=2)
points(ratings.hat3[,1], pch=8, cex=1.5, col='green', lwd=1)
points(ratings.hat4[,1], pch=8, cex=1, col='blue', lwd=1)
points(ratings[,1], pch=21, cex=1, bg='white', lwd=1.5)
legend('bottomright', c('ratings','model1','model2','model1(wo)','model2(wo)'),
       col=c('black','black','red','green','blue'), pch=c(21,3,4,8,8),
       pt.cex=c(1,1.5,1.5,1.5,1), pt.lwd = c(1.5,2,2,1,1))
title("\n Books' ratings", outer=TRUE, cex.main = 2)
for(i in 2:NBooks) {
  plot(ratings.hat1[,i], pch=3, cex=1.5, col='black', lwd=2,
       xlab=paste('book',i), ylab = '', ylim=c(3,9))
  points(ratings.hat2[,i], pch=4, cex=1.5, col='red', lwd=2)
  points(ratings.hat3[,i], pch=8, cex=1.5, col='green', lwd=1)
  points(ratings.hat4[,i], pch=8, cex=1, col='blue', lwd=1)
  points(ratings[,i], pch=21, cex=1, bg='white', lwd=1.5)
  legend('bottomright', c('ratings','model1','model2','model1(wo)','model2(wo)'),
         col=c('black','black','red','green','blue'), pch=c(21,3,4,8,8),
         pt.cex=c(1,1.5,1.5,1.5,1), pt.lwd = c(1.5,2,2,1,1))
}
```

\newpage
\section{5. Users' and books' averages}
```{r 5. users and books averages, fig.height = 6, fig.width = 10, fig.align = "center"}
mod = mod1[[2]]
par(mfrow = c(1,2))
phi = mod$mean$phi

plot((user.m-mean(user.m))/sd(user.m), pch=21, cex=1, bg='black', 
     ylim=c(-5,5), xlab='users', ylab='ratings', 
     main=expression(phi))
points((phi-mean(phi))/sd(phi), pch=21, cex=1, bg='red')
legend('topleft', c('user.m', expression(phi)),
       pch=21, pt.bg=c('black', 'red'), cex=1)


gamma = mod$mean$gamma

plot((book.m-mean(book.m))/sd(book.m), pch=21, cex=1, bg='black', 
     ylim=c(-5,5), xlab='books', ylab='ratings', 
     main=expression(gamma))
points((gamma-mean(gamma))/sd(gamma), pch=21, cex=1, bg='red')
legend('topleft', c('book.m', expression(gamma)),
       pch = 21, pt.bg=c('black', 'red'), cex=1)
```

#### We can try to plot together the users' means with the $\phi$s' estimations, both standardized. The same for the books' means with the $\gamma$s' estimations. The $\phi$s are nearer to the respective means.

\newpage

\section{6. Model: users' and books' averages}
#### In this model we can use $\phi$ and $\gamma$ as weights for the user's and book's means.
#### MODEL
$\texttt{model \{} \\$
$\texttt{\hspace*{1cm}for (i in 1:Nusers) \{} \\$
$\texttt{\hspace*{2cm}for (j in 1:Nbooks) \{} \\$
$\texttt{\hspace*{3cm}ratings[i,j] }$$\sim$$\texttt{dbin(theta[i,j],9)} \\$
$\texttt{\hspace*{3cm}logit.theta[i,j] <- alpha + phi*(user.m[i]-7.35) + gamma*(book.m[j]-7.35)} \\$
$\texttt{\hspace*{3cm}theta[i,j] <- exp(logit.theta[i,j])/(1+exp(logit.theta[i,j]))} \\$
$\texttt{\hspace*{2cm}\}} \\$
$\texttt{\hspace*{1cm}\}} \\$
$\texttt{\hspace*{1cm}alpha}$$\sim$$\texttt{dnorm(0, 0.1)} \\$
$\texttt{\hspace*{1cm}phi}$$\sim$$\texttt{dnorm(0, 0.1)} \\$
$\texttt{\hspace*{1cm}gamma}$$\sim$$\texttt{dnorm(0, 0.1)} \\$
$\texttt{\}} \\$

```{r 6. run model2, message=F}
data = list(Nusers = NUsers, Nbooks = NBooks, ratings = ratings, 
            user.m = user.m, book.m = book.m)
# model

inits = list(alpha = 1, phi = 0, gamma = 0)
mod = jags(data = data,
           inits = list(inits),
           n.chain = 1,
           parameters.to.save=c("alpha","phi","gamma"),
           model.file="model04.txt",
           n.iter = 10000,
           n.burnin = 0,
           n.thin = 1)
```
\newpage
\subsection{6.1 alpha}
\vspace*{.5cm}
```{r 6. alpha, fig.height = 8, fig.width = 20}
print.jags.output1(mod, 'alpha', t=expression(alpha), wb=F)
```

\newpage
\subsection{6.2 phi}
\vspace*{.5cm}
```{r 6. phi, fig.height = 8, fig.width = 20}
print.jags.output1(mod, 'phi', t=expression(phi), wb=F)
```
\newpage
\subsection{6.3 gamma}
\vspace*{.5cm}
```{r 6. gamma, fig.height = 8, fig.width = 20}
print.jags.output1(mod, 'gamma', t=expression(gamma), wb=F)
```
\newpage
```{r, fig.height = 3, fig.width = 6, fig.align = "center", echo=F, eval=F}
cat(expression(paste(theta,d)))
c('mean'=mean(mod[[2]]$mean$theta),'sd'=sd(mod[[2]]$mean$theta))
cat(paste(ratings,d))
c('mean'=mean(mod[[2]]$mean$ratings),'sd'=sd(mod[[2]]$mean$ratings))
```
```{r 6. DIC}
cat(paste('DIC', d, mod[[2]]$DIC))
```

```{r 6. print model}
cat('model ------------------------------------------------\n')
mod[[2]]
DIC3 = mod[[2]]$DIC
dev3 = mod[[2]]$mean[['deviance']]
```
\section{7. Model: no books random effect}
#### MODEL
$\texttt{model \{} \\$
$\texttt{\hspace*{1cm}for (i in 1:Nusers) \{} \\$
$\texttt{\hspace*{2cm}for (j in 1:Nbooks) \{} \\$
$\texttt{\hspace*{3cm}ratings[i,j]}$$\sim$$\texttt{dbin(theta[i,j],9)} \\$
$\texttt{\hspace*{3cm}logit.theta[i,j] <- alpha + phi[i]} \\$
$\texttt{\hspace*{3cm}theta[i,j] <- exp(logit.theta[i,j])/(1+exp(logit.theta[i,j]))} \\$
$\texttt{\hspace*{2cm}\}} \\$
$\texttt{\hspace*{2cm}phi[i]}$$\sim$$\texttt{dnorm(0, tau.u)} \\$
$\texttt{\hspace*{1cm}\}} \\$
$\texttt{\hspace*{1cm}alpha}$$\sim$$\texttt{dnorm(0, tau.alpha)} \\$
$\texttt{\hspace*{1cm}tau.u}$$\sim$$\texttt{dgamma(a.u, b.u)} \\$
$\texttt{\hspace*{1cm}tau.alpha}$$\sim$$\texttt{dgamma(a.alpha, b.alpha)} \\$
$\texttt{\}} \\$
```{r 7. run model3, message=F, warning=F, fig.height = 15, fig.width = 10, fig.align = "center"}
data = list(Nusers = NUsers, Nbooks = NBooks, ratings = ratings, a.u = 1,
            b.u = 1, a.alpha = 1, b.alpha = 1)

inits = list(alpha = 0,
             phi = rep(0,NUsers),
             tau.u = 0.1, tau.alpha = 0.1)
mod = jags(data = data,
           inits = list(inits),
           n.chain = 1,
           parameters.to.save=c("tau.u", "tau.alpha",
                                "phi","alpha"),
           model.file="model03.txt",
           n.iter = 10000,
           n.burnin = 0,
           n.thin = 1)
plot(mod)
```
\newpage
\subsection{7.1 tau.u}
\vspace*{.5cm}
```{r 7. tau.u, fig.height = 8, fig.width = 20}
print.jags.output1(mod, 'tau.u', 
                   t=expression(tau[u]), wb=F)
```
\newpage
\subsection{7.2 tau.alpha}
\vspace*{.5cm}
```{r 7. tau.alpha, fig.height = 8, fig.width = 20}
print.jags.output1(mod, 'tau.alpha',
                   t=expression(tau[alpha]), wb=F)
```
\newpage
\subsection{7.3 alpha}
\vspace*{.5cm}
```{r 7. alpha, fig.height = 8, fig.width = 20}
print.jags.output1(mod, 'alpha', t=expression(alpha), wb=F)
```
\newpage
```{r 7. phi, fig.height = 3, fig.width = 6, fig.align = "center"}
cat(paste('phi',d))
c('mean'=mean(mod[[2]]$mean$phi),'sd'=sd(mod[[2]]$mean$phi))
```

```{r, fig.height = 3, fig.width = 6, fig.align = "center", echo=F, eval=F}
cat(paste('theta', d))
c('mean'=mean(mod[[2]]$mean$theta),'sd'=sd(mod[[2]]$mean$theta))
cat(paste('ratings', d))
c('mean'=mean(mod[[2]]$mean$ratings),'sd'=sd(mod[[2]]$mean$ratings))
```
```{r 7. DIC}
cat(paste('DIC', d, mod[[2]]$DIC))
```
\newpage
```{r 7. print model}
cat('model ------------------------------------------------\n')
mod[[2]]
DIC4 = mod[[2]]$DIC
dev4 = mod[[2]]$mean[['deviance']]
```

\hfill\break
\hfill\break

\section{8. Deviance mean and DIC}

|         | deviance mean | DIC                   |
|---------|------------------------------|-------|
| MODEL1 |  ```r round(dev1,2)``` | ```r round(DIC1,2)```  |
| MODEL2 |  ```r round(dev2,2)``` | ```r round(DIC2,2)```  |
| MODEL1(wo) |  ```r round(dev1wo,2)``` | ```r round(DIC1wo,2)```  |
| MODEL2(wo) |  ```r round(dev2wo,2)``` | ```r round(DIC2wo,2)```  |
| MODEL3 |  ```r round(dev3,2)``` | ```r round(DIC3,2)```  |
| MODEL4 |  ```r round(dev4,2)``` | ```r round(DIC4,2)```  |


The deviance mean of MODEL4 is slightly bigger than the MODEL1's one, since we have a DIC slightly better due to the reduction of the number of parameters (35 for MODEL1 against 23 for MODEL5). MODEL3 has the worst deviance mean but the best DIC (in this case parameters are just $\alpha$, $\phi$ and $\gamma$). MODEL1(wo)'s DIC is computed with *pD=Dbar-Dhat*, with *pD= var(deviance)/2* instead we would obtain 356.8+(10.2^2/2)=408.82. The same for MODEL2(wo)'s DIC which is equal to 393.84.